{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU(\n",
      "  (lstm): GRU(28, 800, num_layers=12, batch_first=True, dropout=0.1, bidirectional=True)\n",
      "  (fc1): Linear(in_features=1600, out_features=800, bias=True)\n",
      "  (fc2): Linear(in_features=800, out_features=1, bias=True)\n",
      "  (fc3): Linear(in_features=400, out_features=1, bias=True)\n",
      "  (conv1): Conv1d(7, 28, kernel_size=(3,), stride=(1,))\n",
      ")\n",
      "epoch:0, train_loss:0.185061, test_loss:0.058782\n",
      "epoch:1, train_loss:0.176119, test_loss:0.030310\n",
      "epoch:2, train_loss:0.180693, test_loss:0.019295\n",
      "epoch:3, train_loss:0.189115, test_loss:0.017973\n",
      "epoch:4, train_loss:0.179182, test_loss:0.017338\n",
      "epoch:5, train_loss:0.189476, test_loss:0.017634\n",
      "epoch:6, train_loss:0.182678, test_loss:0.022646\n",
      "epoch:7, train_loss:0.192675, test_loss:0.021403\n",
      "epoch:8, train_loss:0.183102, test_loss:0.024650\n",
      "epoch:9, train_loss:0.177526, test_loss:0.025788\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import torch.nn.functional as func\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "pio.renderers.default = \"browser\"\n",
    "plotly_config = dict({\"scrollZoom\": True,'modeBarButtonsToAdd':[\n",
    "                                        'drawline',\n",
    "                                        'drawopenpath',\n",
    "                                        'drawclosedpath',\n",
    "                                        'drawcircle',\n",
    "                                        'drawrect',\n",
    "                                        'eraseshape'\n",
    "                                       ]})\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \".*\")\n",
    "\n",
    "data_len = 5 #要輸入的時序訊號長度\n",
    "cap_05 = pd.read_csv(\"features\\charge\\B0005\\B0005_capacity.csv\")\n",
    "cap_07 = pd.read_csv(\"features\\charge\\B0007\\B0007_capacity.csv\")\n",
    "scaler = MinMaxScaler(feature_range = (-1, 1))\n",
    "# features_list = [\"CCCT\",\"CVCT\",\"V37_419\",\"V38_419\",\"V37_41\",\"V38_41\",\"Temperature\",\"cap\"]\n",
    "features_list = [\"CCCT\",\"CVCT\",\"V37_419\",\"V38_419\",\"V37_41\",\"V38_41\",\"Temperature\"]\n",
    "f_len = len(features_list)\n",
    "\n",
    "class temp(Dataset):\n",
    "    def __init__(self, battery_list):\n",
    "        featurelist=[]\n",
    "        capacitylist=[]\n",
    "        for battery in battery_list:\n",
    "            featurelist.append(f\"features\\charge\\{battery}\\{battery}_Features.csv\")\n",
    "            capacitylist.append(f\"features\\charge\\{battery}\\{battery}_capacity.csv\")\n",
    "        \n",
    "        self.feadf = pd.concat((pd.read_csv(f) for f in featurelist), ignore_index=True)\n",
    "        self.capdf = pd.concat((pd.read_csv(f) for f in capacitylist), ignore_index=True)\n",
    "        self.feadf[\"cap\"] = self.capdf[\"Capacity\"]\n",
    "        self.feadf = pd.DataFrame(scaler.fit_transform(self.feadf),\n",
    "                                columns=self.feadf.keys())\n",
    "        self.features = self.feadf.loc[:,features_list].to_numpy()\n",
    "        # print(self.features)\n",
    "        self.capacity = self.capdf[\"Capacity\"].to_numpy()\n",
    "        self.sample_len = data_len\n",
    "\n",
    "    def __len__(self):\n",
    "        if len(self.capdf) > self.sample_len:\n",
    "            return len(self.capdf) - self.sample_len\n",
    "        \n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        target = self.capacity[self.sample_len + index]\n",
    "        target = np.array(target).astype(np.float32)\n",
    "\n",
    "        input = self.features[index : (index + self.sample_len)]\n",
    "        input = torch.from_numpy(input).float()   \n",
    "        # print(input)\n",
    "        input.reshape(-1, f_len)\n",
    "        target = torch.from_numpy(target).float()\n",
    "\n",
    "        return input, target\n",
    "       \n",
    "battery_list = [\"B0005\",\"B0038\",\"B0028\",\"B0033\",\"B0053\",\"B0007\",\"B0028\",\"B0036\",\"B0047\",\"B0029\",\"B0026\",\"B0018\",\"B0039\",\"B0055\",\"B0046\"]\n",
    "train_battery = battery_list\n",
    "train_data = temp(train_battery)\n",
    "\n",
    "test_battery = [\"B0006\",\"B0032\",\"B0034\",\"B0056\",\"B0048\"]\n",
    "test_data = temp(test_battery)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size = 10)\n",
    "test_loader = DataLoader(test_data, batch_size = 10)\n",
    "dataiter = iter(train_loader)\n",
    "data = next(dataiter)\n",
    "features, labels = data\n",
    "\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GRU, self).__init__()\n",
    "\n",
    "        self.input_size = 2*f_len # input size : 輸入維度\n",
    "        self.hidden_size = 800 # hidden_size : 隱藏層的特徵維度\n",
    "        self.num_layers = 12 # hidden_size : GRU隱藏層的層數\n",
    "        self.dropout = 0.1 # dropout : 每一層過後丟棄特定比例神經元\n",
    "\n",
    "        self.lstm = nn.GRU(input_size = self.input_size, hidden_size  = self.hidden_size, bidirectional=True,\n",
    "                            num_layers = self.num_layers, dropout = self.dropout, batch_first = True)\n",
    "        for m in self.modules():\n",
    "            if type(m) in [nn.GRU, nn.GRU, nn.RNN]:\n",
    "                for name, param in m.named_parameters():\n",
    "                    if 'weight_ih' in name:\n",
    "                        torch.nn.init.xavier_uniform_(param.data)\n",
    "                    elif 'weight_hh' in name:\n",
    "                        torch.nn.init.orthogonal_(param.data)\n",
    "                    elif 'bias' in name:\n",
    "                        param.data.fill_(0)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.hidden_size*2, 800)#設定全連接層\n",
    "        self.fc2 = nn.Linear(800, 1)#設定全連接層\n",
    "        self.fc3 = nn.Linear(400, 1)#設定全連接層\n",
    "        self.conv1 = nn.Conv1d(in_channels=f_len, out_channels=2*f_len, kernel_size=3)\n",
    "        # self.conv2 = nn.Conv1d(in_channels=4*f_len, out_channels=8*f_len, kernel_size=3)\n",
    "        # self.conv3 = nn.Conv2d(in_channels=8*data_len, out_channels=16*data_len, kernel_size=3)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        # t = x.unsqueeze_(-1)\n",
    "        # print(t.shape)\n",
    "        x = x.permute(0,2,1)\n",
    "\n",
    "        t = self.conv1(x)\n",
    "        t = func.tanh(t)  \n",
    "        t = func.max_pool1d(t, kernel_size=3,stride=1)\n",
    "\n",
    "        # t = self.conv2(t)\n",
    "        # t = func.tanh(t) \n",
    "        # t = func.max_pool1d(t, kernel_size=3,stride=1)\n",
    "\n",
    "        t = t.permute(0,2,1)\n",
    "        # print(t.shape)\n",
    "        # print(t.shape)\n",
    "        # # second conv layer\n",
    "        # t = self.conv2(t)\n",
    "        # print(t.shape)\n",
    "        # t = func.tanh(t)\n",
    "        # t = func.max_pool2d(t, kernel_size=2, stride=1)\n",
    "        # print(t.shape)\n",
    "        # # third conv layer\n",
    "        # t = self.conv3(t)\n",
    "        # t = func.tanh(t)\n",
    "        # t = func.max_pool2d(t, kernel_size=3, stride=3)\n",
    "        # print(t.shape)\n",
    "        # t = t.view(-1 ,self.input_size, -1)\n",
    "        # print(t.shape)\n",
    "        h_0 = torch.zeros([self.num_layers*2, x.shape[0], self.hidden_size], device = x.device)\n",
    "        c_0 = torch.zeros([self.num_layers*2, x.shape[0], self.hidden_size], device = x.device)\n",
    "\n",
    "        out, _ = self.lstm(t)# x:新資料輸入 h0:上個隱藏層狀態 c0:上個細胞狀態\n",
    "        \n",
    "        out1 = self.fc1(func.tanh(out[:, -1, :]))#接收LSTM單元的輸出，並讓最後一層輸出\n",
    "        out2 = self.fc2(func.tanh(out1))\n",
    "        # out3 = self.fc3(func.tanh(out2))\n",
    "        # out3 = self.fc3(out2)\n",
    "        # out1 = func.tanh(self.fc1(out))\n",
    "        # out2 = func.tanh(self.fc2(out1))\n",
    "        # out3 = self.fc3(out2)#接收LSTM單元的輸出，並讓最後一層輸出\n",
    "\n",
    "        return out2\n",
    "\n",
    "model = GRU()\n",
    "print(model)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "\n",
    "#設定誤差的計算方法\n",
    "loss_f = nn.MSELoss()\n",
    "#設定調整誤差的方法\n",
    "opt = optim.Adam(model.parameters(), lr = 1e-5)\n",
    "\n",
    "def train():\n",
    "    # train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for _, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        pred = model(data)\n",
    "        pred = pred.view(-1)\n",
    "        loss = loss_f(pred, target)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    for _, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        pred = model(data)\n",
    "        pred = pred.view(-1)\n",
    "        loss = loss_f(pred, target)\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def pred(data):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(data)\n",
    "        return pred\n",
    "    \n",
    "train_losses = []\n",
    "test_losses = []\n",
    "epoch = 10\n",
    "for i in range(epoch):\n",
    "    train_loss = train()\n",
    "    test_loss = test()\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print(\"epoch:{}, train_loss:{:0.6f}, test_loss:{:0.6f}\".format(i, train_loss, test_loss))\n",
    "\n",
    "pred_temps = []\n",
    "for i in range(len(test_data)):\n",
    "    nor_temp, taget = test_data[i]\n",
    "    temps = nor_temp\n",
    "    temps = nor_temp.view(1, data_len, f_len)\n",
    "    temps = temps.to(device)\n",
    "    pred_temp = pred(temps)\n",
    "    pred_temp = pred_temp.detach().cpu().numpy().squeeze()\n",
    "\n",
    "    # real_temp = scaler.inverse_transform(pred_temp.reshape(-1, 1))\n",
    "    pred_temps.append(pred_temp)\n",
    "\n",
    "pred_trains = []\n",
    "for i in range(len(train_data)):\n",
    "    nor_temp, taget = train_data[i]\n",
    "    temps = nor_temp\n",
    "    temps = nor_temp.view(1, data_len, f_len)\n",
    "    temps = temps.to(device)\n",
    "    pred_train = pred(temps)\n",
    "    pred_train = pred_train.detach().cpu().numpy().squeeze()\n",
    "\n",
    "    # real_temp = scaler.inverse_transform(pred_temp.reshape(-1, 1))\n",
    "    pred_trains.append(pred_train)\n",
    "\n",
    "# month = data_2.Time\n",
    "capacitytestlist=[]\n",
    "for battery in test_battery:\n",
    "    capacitytestlist.append(f\"features\\charge\\{battery}\\{battery}_capacity.csv\")\n",
    "captestdf = pd.concat((pd.read_csv(f) for f in capacitytestlist), ignore_index=True)\n",
    "\n",
    "capacitytrainlist=[]\n",
    "for battery in train_battery:\n",
    "    capacitytrainlist.append(f\"features\\charge\\{battery}\\{battery}_capacity.csv\")\n",
    "captraindf = pd.concat((pd.read_csv(f) for f in capacitytrainlist), ignore_index=True)\n",
    "\n",
    "mean_temp = captestdf.Capacity.reset_index(drop=True)\n",
    "train_cap = captraindf.Capacity.reset_index(drop=True)\n",
    "\n",
    "torch.save(model.state_dict(),\"./CNN_GRU_model.pth\")\n",
    "\n",
    "fig1 = px.line(train_losses)\n",
    "fig1.update_layout(\n",
    "    dragmode='drawopenpath',\n",
    "    newshape_line_color='cyan',\n",
    "    title_text=f'loss'\n",
    ")\n",
    "# val = pd.DataFrame(pred_trains)\n",
    "# fig.add_scatter(val,x=val.index,y=[\"0\"])\n",
    "fig1.add_scatter(y=test_losses)\n",
    "fig1.show(config=plotly_config)\n",
    "\n",
    "fig = px.line(train_cap)\n",
    "fig.update_layout(\n",
    "    dragmode='drawopenpath',\n",
    "    newshape_line_color='cyan',\n",
    "    title_text=f'train_capacity'\n",
    ")\n",
    "# val = pd.DataFrame(pred_trains)\n",
    "# fig.add_scatter(val,x=val.index,y=[\"0\"])\n",
    "fig.add_scatter(x =list(range(data_len,len(pred_trains)+data_len)) ,y=pred_trains)\n",
    "fig.show(config=plotly_config)\n",
    "\n",
    "fig2 = px.line(mean_temp)\n",
    "fig2.update_layout(\n",
    "    dragmode='drawopenpath',\n",
    "    newshape_line_color='cyan',\n",
    "    title_text=f'test_capacity'\n",
    ")\n",
    "fig2.add_scatter(x =list(range(data_len,len(pred_trains)+data_len)) ,y=pred_temps)\n",
    "fig2.show(config=plotly_config)\n",
    "\n",
    "featurelist=[]\n",
    "capacitylist=[]\n",
    "for battery in battery_list:\n",
    "    featurelist.append(f\"features\\charge\\{battery}\\{battery}_Features.csv\")\n",
    "    capacitylist.append(f\"features\\charge\\{battery}\\{battery}_capacity.csv\")\n",
    "\n",
    "feadf = pd.concat((pd.read_csv(f) for f in featurelist), ignore_index=True)\n",
    "capdf = pd.concat((pd.read_csv(f) for f in capacitylist), ignore_index=True)\n",
    "feadf[\"cap\"] = capdf[\"Capacity\"]*5000\n",
    "feadf[\"Temperature\"] = feadf[\"Temperature\"]*100\n",
    "# fig3 = px.line(feadf,y= [\"CCCT\",\"cap\"])\n",
    "# fig3.update_layout(\n",
    "#     dragmode='drawopenpath',\n",
    "#     newshape_line_color='cyan',\n",
    "#     title_text=f'test_capacity'\n",
    "# )\n",
    "# fig3.show(config=plotly_config)\n",
    "# plt.figure(1)\n",
    "# plt.plot(train_losses, label = 'train_loss')\n",
    "# plt.plot(test_losses, label = 'test_loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure(2)\n",
    "# plt.plot(mean_temp, label = \"org_data\", color = 'b')\n",
    "# plt.plot(pred_temps, label = \"pred_data\", color = 'r')\n",
    "# plt.title(\"test\")\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure(3)\n",
    "# plt.plot(train_cap, label = \"org_data\", color = 'b')\n",
    "# plt.plot(pred_trains, label = \"pred_data\", color = 'r')\n",
    "# plt.title(\"train\")\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soh-estimited-HqnS-wet-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
