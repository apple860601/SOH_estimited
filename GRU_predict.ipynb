{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'features\\\\charge\\\\B0005\\\\B0005_capacity.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m.*\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m data_len \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m \u001b[39m#要輸入的時序訊號長度\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m cap_05 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mfeatures\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mcharge\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mB0005\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mB0005_capacity.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     31\u001b[0m cap_07 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mcharge\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mB0007\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mB0007_capacity.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m scaler \u001b[39m=\u001b[39m MinMaxScaler(feature_range \u001b[39m=\u001b[39m (\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\soh-estimited-HqnS-wet-py3.10\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\soh-estimited-HqnS-wet-py3.10\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\soh-estimited-HqnS-wet-py3.10\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\soh-estimited-HqnS-wet-py3.10\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\soh-estimited-HqnS-wet-py3.10\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'features\\\\charge\\\\B0005\\\\B0005_capacity.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import torch.nn.functional as func\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "pio.renderers.default = \"browser\"\n",
    "plotly_config = dict({\"scrollZoom\": True,'modeBarButtonsToAdd':[\n",
    "                                        'drawline',\n",
    "                                        'drawopenpath',\n",
    "                                        'drawclosedpath',\n",
    "                                        'drawcircle',\n",
    "                                        'drawrect',\n",
    "                                        'eraseshape'\n",
    "                                       ]})\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \".*\")\n",
    "\n",
    "data_len = 3 #要輸入的時序訊號長度\n",
    "cap_05 = pd.read_csv(\"features\\charge\\B0005\\B0005_capacity.csv\")\n",
    "cap_07 = pd.read_csv(\"features\\charge\\B0007\\B0007_capacity.csv\")\n",
    "scaler = MinMaxScaler(feature_range = (-2, 2))\n",
    "# features_list = [\"CCCT\",\"CVCT\",\"V37_419\",\"V38_419\",\"V37_41\",\"V38_41\",\"Temperature\",\"cap\"]\n",
    "features_list = [\"CCCT\",\"CVCT\",\"V37_419\",\"V38_419\",\"V37_41\",\"V38_41\",\"cap\"]\n",
    "f_len = len(features_list)\n",
    "\n",
    "class temp(Dataset):\n",
    "    def __init__(self, battery_list):\n",
    "        featurelist=[]\n",
    "        capacitylist=[]\n",
    "        for battery in battery_list:\n",
    "            featurelist.append(f\"features\\charge\\{battery}\\{battery}_Features.csv\")\n",
    "            capacitylist.append(f\"features\\charge\\{battery}\\{battery}_capacity.csv\")\n",
    "        \n",
    "        self.feadf = pd.concat((pd.read_csv(f) for f in featurelist), ignore_index=True)\n",
    "        self.capdf = pd.concat((pd.read_csv(f) for f in capacitylist), ignore_index=True)\n",
    "        self.feadf[\"cap\"] = self.capdf[\"Capacity\"]\n",
    "        self.feadf = pd.DataFrame(scaler.fit_transform(self.feadf),\n",
    "                                columns=self.feadf.keys())\n",
    "        self.features = self.feadf.loc[:,features_list].to_numpy()\n",
    "        # print(self.features)\n",
    "        self.capacity = self.capdf[\"Capacity\"].to_numpy()\n",
    "        self.sample_len = data_len\n",
    "\n",
    "    def __len__(self):\n",
    "        if len(self.capdf) > self.sample_len:\n",
    "            return len(self.capdf) - self.sample_len\n",
    "        \n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        target = self.capacity[self.sample_len + index]\n",
    "        target = np.array(target).astype(np.float32)\n",
    "\n",
    "        input = self.features[index : (index + self.sample_len)]\n",
    "        input = torch.from_numpy(input).float()   \n",
    "        # print(input)\n",
    "        input.reshape(-1, f_len)\n",
    "        target = torch.from_numpy(target).float()\n",
    "\n",
    "        return input, target\n",
    "       \n",
    "battery_list = [\"B0005\",\"B0038\",\"B0028\",\"B0033\",\"B0053\",\"B0007\",\"B0028\",\"B0036\",\"B0047\",\"B0029\",\"B0026\",\"B0018\",\"B0039\",\"B0055\",\"B0046\"]\n",
    "train_battery = battery_list\n",
    "train_data = temp(train_battery)\n",
    "\n",
    "test_battery = [\"B0006\"]\n",
    "test_data = temp(test_battery)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size = 3)\n",
    "test_loader = DataLoader(test_data, batch_size = 3)\n",
    "dataiter = iter(train_loader)\n",
    "data = next(dataiter)\n",
    "features, labels = data\n",
    "\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GRU, self).__init__()\n",
    "\n",
    "        self.input_size = f_len # input size : 輸入維度\n",
    "        self.hidden_size = 400 # hidden_size : 隱藏層的特徵維度\n",
    "        self.num_layers = 8 # hidden_size : LSTM隱藏層的層數\n",
    "        self.dropout = 0.1 # dropout : 每一層過後丟棄特定比例神經元\n",
    "\n",
    "        self.gru = nn.GRU(input_size = self.input_size, hidden_size  = self.hidden_size, bidirectional=True,\n",
    "                            num_layers = self.num_layers, dropout = self.dropout, batch_first = True)\n",
    "        for m in self.modules():\n",
    "            if type(m) in [nn.GRU, nn.GRU, nn.RNN]:\n",
    "                for name, param in m.named_parameters():\n",
    "                    if 'weight_ih' in name:\n",
    "                        torch.nn.init.xavier_uniform_(param.data)\n",
    "                    elif 'weight_hh' in name:\n",
    "                        torch.nn.init.orthogonal_(param.data)\n",
    "                    elif 'bias' in name:\n",
    "                        param.data.fill_(0.1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.hidden_size*2, 600)#設定全連接層\n",
    "        self.fc2 = nn.Linear(600, 600)#設定全連接層\n",
    "        self.fc3 = nn.Linear(600, 600)#設定全連接層\n",
    "        self.fc4 = nn.Linear(600, 1)#設定全連接層\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        h_0 = torch.zeros([self.num_layers*2, x.shape[0], self.hidden_size], device = x.device)\n",
    "        c_0 = torch.zeros([self.num_layers*2, x.shape[0], self.hidden_size], device = x.device)\n",
    "\n",
    "        out, _ = self.gru(x,h_0)# x:新資料輸入 h0:上個隱藏層狀態 c0:上個細胞狀態\n",
    "        # print(out.shape)\n",
    "        out = self.fc1(func.tanh(out[:, -1, :]))#接收LSTM單元的輸出，並讓最後一層輸出\n",
    "        out = self.fc2(func.tanh(out))\n",
    "        out = self.fc3(func.tanh(out))\n",
    "        out = self.fc4(func.tanh(out))\n",
    "        # out3 = self.fc3(out2)\n",
    "        # out1 = func.tanh(self.fc1(out))\n",
    "        # out2 = func.tanh(self.fc2(out1))\n",
    "        # out3 = self.fc3(out2)#接收LSTM單元的輸出，並讓最後一層輸出\n",
    "\n",
    "        return out\n",
    "\n",
    "model = GRU()\n",
    "print(model)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "\n",
    "#設定誤差的計算方法\n",
    "loss_f = nn.MSELoss()\n",
    "#設定調整誤差的方法\n",
    "opt = optim.Adam(model.parameters(), lr = 5e-7)\n",
    "\n",
    "def train():\n",
    "    # train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for _, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        pred = model(data)\n",
    "\n",
    "        pred = pred.view(-1)\n",
    "\n",
    "        loss = loss_f(pred, target)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    for _, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        pred = model(data)\n",
    "        pred = pred.view(-1)\n",
    "        loss = loss_f(pred, target)\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "def pred(data):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(data)\n",
    "        return pred\n",
    "    \n",
    "train_losses = []\n",
    "test_losses = []\n",
    "epoch = 200\n",
    "for i in range(epoch):\n",
    "    train_loss = train()\n",
    "    test_loss = test()\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print(\"epoch:{}, train_loss:{:0.6f}, test_loss:{:0.6f}\".format(i, train_loss, test_loss))\n",
    "\n",
    "pred_temps = []\n",
    "for i in range(len(test_data)):\n",
    "    nor_temp, taget = test_data[i]\n",
    "    temps = nor_temp\n",
    "    temps = nor_temp.view(1, data_len, f_len)\n",
    "    temps = temps.to(device)\n",
    "    pred_temp = pred(temps)\n",
    "    pred_temp = pred_temp.detach().cpu().numpy().squeeze()\n",
    "\n",
    "    # real_temp = scaler.inverse_transform(pred_temp.reshape(-1, 1))\n",
    "    pred_temps.append(pred_temp)\n",
    "\n",
    "pred_trains = []\n",
    "for i in range(len(train_data)):\n",
    "    nor_temp, taget = train_data[i]\n",
    "    temps = nor_temp\n",
    "    temps = nor_temp.view(1, data_len, f_len)\n",
    "    temps = temps.to(device)\n",
    "    pred_train = pred(temps)\n",
    "    pred_train = pred_train.detach().cpu().numpy().squeeze()\n",
    "\n",
    "    # real_temp = scaler.inverse_transform(pred_temp.reshape(-1, 1))\n",
    "    pred_trains.append(pred_train)\n",
    "\n",
    "# month = data_2.Time\n",
    "capacitytestlist=[]\n",
    "for battery in test_battery:\n",
    "    capacitytestlist.append(f\"features\\charge\\{battery}\\{battery}_capacity.csv\")\n",
    "captestdf = pd.concat((pd.read_csv(f) for f in capacitytestlist), ignore_index=True)\n",
    "\n",
    "capacitytrainlist=[]\n",
    "for battery in train_battery:\n",
    "    capacitytrainlist.append(f\"features\\charge\\{battery}\\{battery}_capacity.csv\")\n",
    "captraindf = pd.concat((pd.read_csv(f) for f in capacitytrainlist), ignore_index=True)\n",
    "\n",
    "mean_temp = captestdf.Capacity.reset_index(drop=True)\n",
    "train_cap = captraindf.Capacity.reset_index(drop=True)\n",
    "\n",
    "torch.save(model.state_dict(),\"./GRU_model.pth\")\n",
    "\n",
    "fig1 = px.line(train_losses)\n",
    "fig1.update_layout(\n",
    "    dragmode='drawopenpath',\n",
    "    newshape_line_color='cyan',\n",
    "    title_text=f'loss'\n",
    ")\n",
    "# val = pd.DataFrame(pred_trains)\n",
    "# fig.add_scatter(val,x=val.index,y=[\"0\"])\n",
    "fig1.add_scatter(y=test_losses)\n",
    "fig1.show(config=plotly_config)\n",
    "\n",
    "fig = px.line(train_cap)\n",
    "fig.update_layout(\n",
    "    dragmode='drawopenpath',\n",
    "    newshape_line_color='cyan',\n",
    "    title_text=f'train_capacity'\n",
    ")\n",
    "# val = pd.DataFrame(pred_trains)\n",
    "# fig.add_scatter(val,x=val.index,y=[\"0\"])\n",
    "fig.add_scatter(y=pred_trains)\n",
    "fig.show(config=plotly_config)\n",
    "\n",
    "fig2 = px.line(mean_temp)\n",
    "fig2.update_layout(\n",
    "    dragmode='drawopenpath',\n",
    "    newshape_line_color='cyan',\n",
    "    title_text=f'test_capacity'\n",
    ")\n",
    "fig2.add_scatter(y=pred_temps)\n",
    "fig2.show(config=plotly_config)\n",
    "\n",
    "featurelist=[]\n",
    "capacitylist=[]\n",
    "for battery in battery_list:\n",
    "    featurelist.append(f\"features\\charge\\{battery}\\{battery}_Features.csv\")\n",
    "    capacitylist.append(f\"features\\charge\\{battery}\\{battery}_capacity.csv\")\n",
    "\n",
    "feadf = pd.concat((pd.read_csv(f) for f in featurelist), ignore_index=True)\n",
    "capdf = pd.concat((pd.read_csv(f) for f in capacitylist), ignore_index=True)\n",
    "feadf[\"cap\"] = capdf[\"Capacity\"]*5000\n",
    "feadf[\"Temperature\"] = feadf[\"Temperature\"]*100\n",
    "# fig3 = px.line(feadf,y= list(feadf.columns))\n",
    "# fig3.update_layout(\n",
    "#     dragmode='drawopenpath',\n",
    "#     newshape_line_color='cyan',\n",
    "#     title_text=f'test_capacity'\n",
    "# )\n",
    "# fig3.show(config=plotly_config)\n",
    "# plt.figure(1)\n",
    "# plt.plot(train_losses, label = 'train_loss')\n",
    "# plt.plot(test_losses, label = 'test_loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure(2)\n",
    "# plt.plot(mean_temp, label = \"org_data\", color = 'b')\n",
    "# plt.plot(pred_temps, label = \"pred_data\", color = 'r')\n",
    "# plt.title(\"test\")\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure(3)\n",
    "# plt.plot(train_cap, label = \"org_data\", color = 'b')\n",
    "# plt.plot(pred_trains, label = \"pred_data\", color = 'r')\n",
    "# plt.title(\"train\")\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soh-estimited-HqnS-wet-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
